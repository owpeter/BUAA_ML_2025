# 机器学习数学基础：概率统计与矩阵知识梳理

## 概率统计理论基础

概率统计是机器学习中不可或缺的基石，它为理解数据、构建模型和评估结果提供了理论支撑。

### 随机试验与随机事件

* **随机试验**：指在一定条件下，结果不确定的观测或试验。
* **随机事件**：随机试验可能发生的结果，分为必然事件、不可能事件和随机事件。
* **事件关系与运算**：包括事件的包含 ($A\subset B$)、相等 ($A=B$)、积/交 ($A\cap B$)、互不相容 ($A\cap B=\Phi$)、和/并 ($A\cup B$)、对立 ($\overline{A}$)、差 ($A-B$)。事件间的运算满足交换律、结合律、分配律和对偶原则。

### 概率基本概念与重要公式

* **概率 (Probability)**：度量随机事件发生可能性大小的数值，满足非负性 ($0\le P(A)\le1$)、规范性 ($P(S)=1, P(\Phi)=0$)、有限可加性和互补性 ($P(\overline{A})=1-P(A)$)等性质。
* **联合概率 (Joint Probability)**：事件A和B共同发生的概率，记作 $P(A,B)$ 或 $P(A\cap B)$ 。
* **条件概率 (Conditional Probability)**：事件B已发生的条件下，事件A发生的概率，记作 $P(A|B)$ 。
* **独立事件 (Independent Events)**：事件A的发生不影响事件B发生的概率。
* **条件独立 (Conditional Independence)**：在给定事件C的条件下，事件A和B相互独立。
* **乘法公式 (Multiplication Theorem/Formula)**：$P(A,B)=P(A|B)\cdot P(B) =P(B|A)\cdot P(A)$ 。可推广到多个事件。
* **全概率公式 (Law of Total Probability)**：用于已知原因求结果的概率，$P(B)=\sum_{k=1}^{n}P(A_{k})P(B|A_{k})$ 。
* **贝叶斯公式 (Bayes' Theorem)**：用于已知结果求原因的概率，$P(B_{i}|A)=\frac{P(B_{i})P(A|B_{i})}{\sum_{j=1}^{n}P(B_{j})P(A|B_{j})}$ 。它连接了先验概率、似然概率和后验概率。

### 随机变量及其数字特征

* **随机变量**：将随机试验结果映射到实数上的函数。
* **概率分布函数 (CDF)**：描述随机变量取值不超过某个实数的概率，$F(x)=P(X\le x)$ 。具有单调不减、非负有界、右连续等性质。
* **离散型随机变量**：取值是有限或可数无限个的随机变量，其概率分布可用概率分布律表示。
* **连续型随机变量**：取值是不可数无限个的随机变量，其概率分布可用概率密度函数 (PDF) 描述。
* **期望 (Expectation)**：随机变量的概率平均值。
* **方差 (Variance)**：描述随机变量值偏离期望值的程度。
* **标准差 (Standard Deviation)**：方差的平方根。
* **矩**：包括原点矩和中心矩。
* **协方差 (Covariance)**：衡量两个随机变量线性相关程度。
* **相关系数 (Correlation Coefficient)**：标准化的协方差，$-1 \le \rho_{XY} \le 1$。
* **高斯分布 (Gaussian Distribution)**：机器学习中常见的概率分布，包括一维和多维形式。

### 概率密度函数估计

根据样本数据估计概率密度函数 $p(x)$。

* **参数化方法 (Parametric Methods)**：假设概率密度函数形式已知，估计未知参数。
    * **最大似然估计 (Maximum Likelihood Estimation, MLE)**：选择使似然函数（观测到样本集的概率密度）最大的参数值作为估计值。需要求解似然函数或对数似然函数的导数为零的方程。
    * 估计量的性质与评价标准：无偏性、渐近无偏性、有效性、一致性。
* **非参数化方法 (Nonparametric Methods)**：概率密度函数形式未知，直接依据样本估计总体分布。
    * **直方图方法**：将数据空间划分成小区域，统计落入各区域的样本数来估计概率密度。
    * **Parzen窗法 (Parzen Window Method)**：使用窗函数对样本进行加权，估计概率密度。
    * **k近邻法 (k-nearest Neighbor Method)**：固定落入区域内的样本数k，通过确定包含k个近邻的区域体积来估计概率密度。

## 矩阵基础概念 (课后拓展)

矩阵是处理多维数据和线性变换的重要工具。

### 矩阵的定义与特殊矩阵

* **矩阵**：由m行n列数组成的数表。
* **特殊矩阵**：方阵 (行数=列数)、行矩阵、列矩阵、零矩阵 (所有元素为零)、单位矩阵 (主对角线为1，其余为0)、对角矩阵 (非主对角线元素为0)、对称矩阵 ($a_{ij} = a_{ji}$)。
* **行列式与矩阵的区别**：行列式是一个数值，矩阵是一个数表。

### 矩阵的运算

* **加法**：同型矩阵对应元素相加。
* **数乘**：数与矩阵中每个元素相乘。
* **乘法**：第一个矩阵的列数等于第二个矩阵的行数时才能相乘。矩阵乘法不满足交换律。
* **幂**：方阵的多次相乘。
* **转置**：矩阵的行换成同序数的列得到的新矩阵。
* **逆矩阵**：对于方阵A，如果存在矩阵B使得 $AB=BA=E$，则B为A的逆矩阵，记作 $A^{-1}$。逆矩阵具有唯一性。
* **秩 (Rank)**：矩阵中不等于零的最高阶子式的阶数。
* **迹 (Trace)**：方阵主对角线元素之和。
* **求导**：向量对向量的求导得到Jacobian矩阵。

# 机器学习模型评估与选择：核心概念与方法

## 机器学习基础回顾

首先，回顾机器学习的定义：一个计算机程序如果在任务T上，用性能指标P衡量，随经验E的增加，性能得到提高，则称该程序从经验E中学习到了任务T。根据输出变量的类型和学习方式，机器学习主要分为监督学习（分类、回归）、无监督学习（聚类、降维）以及半监督学习。

* **监督学习**：数据拥有标签。
    * **分类**：输出是离散值，如手写数字识别。
    * **回归**：输出是连续值，如天气预测。
* **无监督学习**：数据没有标签。
    * **聚类**：将数据分组。
    * **降维**：减少数据维度。

分类和回归任务有不同的训练和测试过程，核心在于从带有标签的训练数据中学习规律，并对新的测试数据进行预测。

## 模型评估与选择的核心问题

模型的**误差**是预测输出与真实输出之间的差异。
* **训练误差**或**经验误差**：模型在训练集上的误差。
* **测试误差（Testing error）**：模型在新样本上的误差，反映模型的**泛化能力**。

模型评估与选择的目标是选择在未知数据上表现最好的模型，即最小化测试误差。这通常包括以下步骤：
1.  将数据集划分为训练集和测试集。
2.  在训练集上训练模型。
3.  在测试集上评估模型的泛化性能。
4.  基于评估结果进行模型选择。

## 数据集划分方法

为了客观评估模型的泛化能力，需要将数据集进行划分。常用的方法包括：

* **留出法（Hold-out）**：将数据集随机划分为训练集和测试集。通常采用2/3数据用于训练，1/3用于测试。优点是简单易行，缺点是受数据划分方式影响较大。
* **随机子抽样（Random Sub-sampling）**：多次重复留出法，取平均结果。可以减少单次划分带来的偏差，但每个样本被用于训练的次数不同。
* **k折交叉验证（k-fold Cross-validation）**：将数据集划分为k个大小相似的互斥子集。每次用k-1个子集训练，1个子集测试，重复k次。每个样本都被用于测试一次，用于训练k-1次。相比留出法和随机子抽样，评估结果更稳定可靠。
* **留一法（Leave-one-out）**：k折交叉验证的特殊情况，k等于样本总数。每次只留下一个样本做测试。评估结果比较准确，但计算量巨大，适用于数据集较小的情况。
* **自助法（Bootstrapping）**：通过有放回地从数据集中抽样，生成多个与原数据集大小相同的训练集。未被抽到的样本组成测试集。约有36.8%的样本不会被抽到。适用于数据集较小的情况，能够产生多个不同的训练集，对集成学习有利，但改变了数据集的初始分布，可能引入估计偏差。

不同的划分方法有各自的适用场景以及对方差和偏差的影响。

## 模型的性能度量

根据任务类型，有不同的性能度量指标。

### 回归任务

主要使用误差来衡量预测值与真实值之间的差距：
* **平均绝对误差（Mean Absolute Error, MAE）**：$E(f;D)=\frac{1}{n}\sum_{i=1}^{n}|f(x_{i})-y_{i}|$
* **均方误差（Mean Squared Error, MSE）**：$E(f;D)=\frac{1}{n}\sum_{i=1}^{n}(f(x_{i})-y_{i})^{2}$

### 分类任务

基本指标包括：
* **错误率**：分类错误的样本数占总样本数的比例。
* **准确率**：分类正确的样本数占总样本数的比例，1 - 错误率。
错误率和准确率直观且计算简单，但在数据类别不均衡时可能无法全面反映模型性能。

为了更详细地评估分类器性能，特别是处理类别不平衡问题时，引入以下概念和指标，通常基于**混淆矩阵（Confusion Matrix）**：

对于二分类问题（正例P，负例N）：

| 真实类别 \\ 预测结果 | 正例 P | 负例 N |
| :---------- | :----: | :----: |
| **正例 P** | 真正例 TP | 假负例 FN |
| **负例 N** | 假正例 FP | 真负例 TN |

> 这里对表中的四个概念进行一些解释：真正例指被分类器正确分类的正元组，真负例指被分类器正确分类的负元组，假正例指被分类器错标称正的负元组，加负例指被分类器错标为负的正元组

* **准确率（Accuracy）**：$accuracy = (TP+TN)/(P+N)$
* **错误率（ErrorRate）**：$ErrorRate = (FP+FN)/(P+N)$
* **查准率（Precision）**：预测为正例的样本中，真正例的比例。 $percision = TP/(TP+FP)$。衡量模型预测正例的准确性。
* **查全率（Recall）**或**敏感性（Sensitivity）**：所有真正例中，被模型正确识别为正例的比例 $recall = TP/P = TP/(TP+FN)$。衡量模型找出所有正例的能力。
* **真阳性率（True Positive Rate, TPR）**：等同于查全率。
* **真阴性率（True Negative Rate, TNR）**或**特异性（Specificity）**：所有真负例中，被模型正确识别为负例的比例 $TN/N = TN/(TN+FP)$。衡量模型找出所有负例的能力。
* **假阳性率（False Positive Rate, FPR）**：所有真负例中，被模型错误识别为正例的比例 $FP/N = FP/(FP+TN)$。

查准率和查全率往往存在矛盾，可以通过 **P-R曲线 Precision-Recall Curve**来可视化模型在不同阈值下的查准率和查全率表现。

综合查准率和查全率的指标：
* **F1度量**：查准率和查全率的调和平均，$F1 = 2 \times (Precision \times Recall) / (Precision + Recall)$。
* **F$_\beta$度量**：允许调整查全率对查准率的相对重要性，$F_\beta = (1+\beta^2) \times (Precision \times Recall) / (\beta^2 \times Precision + Recall)$。$\beta > 1$时更侧重查全率，$\beta < 1$时更侧重查准率。

其他重要的分类评估工具包括：
* **ROC曲线（Receiver Operating Characteristic Curve）**：以TPR为纵坐标，FPR为横坐标，反映模型在不同阈值下识别正例和负例的能力。 [cite: 50]
* **AUC（Area Under Curve）**：ROC曲线下的面积，用于衡量模型的整体性能，AUC值越大，模型性能越好。 [cite: 51]

### 代价敏感性能度量

在某些应用中，不同类型的错误可能导致不同的损失。**代价敏感性能度量**考虑了这一点，通过**代价矩阵（Cost Matrix）**定义不同误分类的代价，并计算**代价敏感错误率**。

# 贝叶斯决策理论：让机器做出更明智的判断

在机器学习领域，我们经常面临如何让机器根据已有数据做出最优决策的问题。贝叶斯决策理论正是解决此类问题的一大利器，它为我们提供了一个在不确定性条件下进行最优决策的数学框架。本文将带您梳理贝叶斯决策理论的核心概念，助您理解机器如何“思考”并做出判断。

## 一、概率论基础回顾：决策的基石

在深入贝叶斯决策理论之前，我们首先需要回顾几个关键的概率论概念，它们是理解贝叶斯决策的基石。

* **乘法公式**：用于计算多个事件同时发生的概率。简单来说，事件A和事件B同时发生的概率等于在事件B发生的条件下事件A发生的概率乘以事件B发生的概率，即 $P(A,B) = P(A|B) \cdot P(B)$。这个公式可以推广到多个事件的情况。
* **全概率公式**：当某个事件B的发生总是伴随着一系列互不相容的事件 $A_1, A_2, ..., A_n$ 之一发生时，事件B的概率可以通过对所有$P(A_k)P(B|A_k)$ 求和得到。它描述了“知因求果”的过程，即在已知各种原因发生的概率及其导致结果发生的条件下，计算结果发生的总概率。
* **贝叶斯公式**：这是贝叶斯决策理论的核心。它恰好与全概率公式相反，描述了“知果求因”的过程。即在结果事件B已经发生的条件下，推断某个原因事件 $A_k$ 发生的条件概率。其基本形式为：
$$
\begin{aligned}
    P(A_k|B) = \frac{P(A_k)P(B|A_k)}{\sum_{i=1}^{n}P(A_i)P(B|A_i)}, k\in 1,2,..,n
\end{aligned}
$$

公式中的 $P(A_k)$ 被称为**先验概率**（在观测到结果B之前对原因 $A_k$ 的判断），而 $P(A_k|B)$ 被称为**后验概率**（在观测到结果B之后对原因 $A_k$ 的修正判断）。贝叶斯公式告诉我们，对结果的任何观测都将增加我们对原因事件真实分布的认识。

## 二、贝叶斯决策理论：核心思想与应用

贝叶斯决策理论的目标是在各种可能的决策中选择期望损失最小的决策。在分类问题中，这意味着将样本划分到后验概率最大的那个类别。

### 1. 基本概念

在讨论贝叶斯决策之前，我们先明确几个基本概念：

* **样本 (Sample)**：通常表示为一个d维向量 $x \in R^d$，代表我们观察到的一个具体实例。
* **类别/状态 (Class/State)**：用 $\omega_i$ 表示，代表样本可能属于的不同类别。
* **先验概率 (Prior Probability)**：$P(\omega_i)$，表示在没有任何其他信息的情况下，某个类别 $\omega_i$ 本身出现的概率。
* **类条件概率密度 (Class-conditional Probability Density)**：$p(x|\omega_i)$，表示在已知样本属于类别 $\omega_i$ 的条件下，观察到样本$x$的概率密度。
* **样本分布密度 (Sample Distribution Density)**：$p(x)$，表示观察到样本x的概率密度，可以通过全概率公式计算得到：$p(x) = \sum_{i} p(x|\omega_i)P(\omega_i)$。

### 2. 最小错误率贝叶斯决策

这是贝叶斯决策中最常用的一种策略。其核心思想是：对于一个给定的样本x，我们计算它属于各个类别的后验概率 $P(\omega_i|x)$，然后选择具有最大后验概率的那个类别作为决策结果。这样做可以使得总体分类错误率最小。

根据贝叶斯公式，$P(\omega_i|x) = \frac{p(x|\omega_i)P(\omega_i)}{p(x)}$。由于对于同一个样本x，其 $p(x)$ 是相同的，因此比较后验概率 $P(\omega_i|x)$ 的大小，等价于比较 $p(x|\omega_i)P(\omega_i)$ 的大小。

所以，最小错误率贝叶斯决策的规则可以表示为：若 $p(x|\omega_i)P(\omega_i) > p(x|\omega_j)P(\omega_j)$ 对所有 $j \neq i$ 成立，则判决 $x \in \omega_i$。

> 举个例子：假设我们将某工厂生成的零件分为A B两类，两类产品的先验概率为：
>
> - $P(\omega_A) = 0.6$
> - $P(\omega_B) = 0.4$
>
> 且已知类条件概率密度函数服从正态分布：
> - $p(x|\omega_A)$均值为5，标准差为1
> - $p(x|\omega_B)$均值为8，标准差为1.5
>
> 那么对于一个新的长度为$x_{new}$的零件，我们只需要计算$p(x_{new}|\omega_A)P(\omega_A)$与$p(x_{new}|\omega_B)P(\omega_B)$哪个更大，即将新的零件归为哪类的后验概率更大，就将其归为哪类。

### 3. 最小风险贝叶斯决策

在某些场景下，不同的错分带来的损失是不同的。例如，在医疗诊断中，将病人误诊为健康（漏诊）和将健康人误诊为病人（误诊）所带来的风险可能不同。最小风险贝叶斯决策考虑了这种不同错分带来的损失。

它引入了一个**损失函数** $\lambda(\alpha_i|\omega_j)$，表示当真实类别是 $\omega_j$ 时，我们采取决策 $\alpha_i$ (即将样本判为类别i) 所带来的损失。那么，对于一个样本x，采取决策 $\alpha_i$ 的**条件风险** (Conditional Risk) 可以表示为所有可能真实类别的期望损失：$R(\alpha_i|x) = \sum_{j=1}^{c} \lambda(\alpha_i|\omega_j)P(\omega_j|x)$，其中c是类别总数。

最小风险贝叶斯决策的规则是：计算样本x采取每个可能决策 $\alpha_i$ 时的条件风险 $R(\alpha_i|x)$，然后选择使得条件风险最小的那个决策。

可以证明，最小错误率贝叶斯决策是最小风险贝叶斯决策在损失函数取特定值（例如，正确分类损失为0，错误分类损失为1）时的一个特例。

### 4. 朴素贝叶斯决策

在实际应用中，直接估计类条件概率密度 $p(x|\omega_i)$ 往往非常困难，尤其是当样本x的维度很高时。朴素贝叶斯决策为了简化计算，做了一个很强的假设：**给定类别时，样本的各个特征之间是条件独立的。**

这意味着 $p(x|\omega_i) = p(x_1, x_2, ..., x_d|\omega_i) = \prod_{k=1}^{d} p(x_k|\omega_i)$，其中 $x_k$ 是样本x的第k个特征。

尽管这个独立性假设在现实中往往不成立，但朴素贝叶斯分类器在很多情况下仍然表现出惊人的良好性能，并且计算简单、易于实现。

### 5. 贝叶斯估计

在前面的讨论中，我们假设先验概率 $P(\omega_i)$ 和类条件概率密度 $p(x|\omega_i)$ 是已知的。但在实际问题中，它们往往是未知的，需要从训练数据中进行估计。贝叶斯估计提供了一种估计这些概率参数的方法。与最大似然估计等方法不同，贝叶斯估计将待估计的参数也看作是随机变量，并为其引入先验分布，然后根据观测数据计算其后验分布。

## 总结

贝叶斯决策理论为我们提供了一个强大而灵活的框架，用于在不确定性下做出最优决策。从基本的概率回顾到最小错误率、最小风险以及朴素贝叶斯决策，再到参数的贝叶斯估计，这一理论贯穿了机器学习的诸多方面。理解贝叶斯决策的原理，不仅能帮助我们更好地应用相关的机器学习算法，也能启发我们对智能决策过程的深入思考。


# 机器学习中的线性模型：回归与分类

在线性模型中，我们探索如何使用简单的线性关系来解决复杂的机器学习问题，主要分为回归和分类两大任务。

## 初识线性模型

机器学习算法大致可分为监督学习和无监督学习。监督学习进一步细分为处理离散输出的分类问题和处理连续输出的回归问题。无监督学习则包括聚类和降维等任务。以下将重点讨论监督学习中的线性模型，特别是回归和分类。

## 回归：预测连续值

**回归的起源与概念**

“回归”一词最早由英国生物学家弗朗西斯·高尔顿（Francis Galton）提出。他在研究父母身高与子女身高关系时发现，如果父母身高高于平均身高，其子女身高倾向于“回归”到大众平均身高；反之亦然。

在机器学习中，回归的目标是找到一个函数，将输入变量映射到一个或多个连续的输出变量，并使预测值与真实值之间的差距尽可能小。例如，根据房屋的面积、卧室数量、房龄等特征来预测房价。

**线性回归模型**

最简单的回归模型是线性回归，它假设输出是输入特征的线性组合。其数学表达式可以写成：
$$
\begin{aligned}
    f(x) = w_0 + w_1x_1 + ... + w_mx_m = \mathbf{w}^T\mathbf{x}
\end{aligned}
$$

其中，$\mathbf{w}$ 是模型参数（权重），$\mathbf{x}$ 是输入特征向量（为了包含截距项 $w_0$，通常会增加一个恒为1的特征 $x_0$）。

为了增强模型的表达能力，可以使用基函数（Basis Functions）对原始输入特征进行变换。常见的基函数包括多项式基函数、高斯基函数和Sigmoid基函数。变换后的模型仍然是关于参数 $\mathbf{w}$ 的线性模型：
$$
\begin{aligned}
    y(x, \mathbf{w}) = \sum_{j=0}^{M-1} w_j \phi_j(x) = \mathbf{w}^T\mathbf{\phi}(x)
\end{aligned}
$$

**求解回归问题**

求解线性回归问题的核心是确定模型参数 $\mathbf{w}$。基本思想是最小化预测值与真实输出值之间的差异。这通常通过定义一个目标函数（代价函数）来实现，最常用的是均方误差：
$$
\begin{aligned}
    J(\mathbf{w}) = \frac{1}{2}\sum_{i=1}^{N}(f(\mathbf{x}_i) - y_i)^2
\end{aligned}
$$

目标是找到使 $J(\mathbf{w})$ 最小的 $\mathbf{w}$。

我们有两种主要方法来求解这个问题：

1.  **标准方程组 (Normal Equations)**:
    通过直接对代价函数求导并令其等于0，可以得到参数 $\mathbf{w}$ 的解析解。将代价函数写成矩阵形式 $J(\mathbf{w}) = (\mathbf{X}\mathbf{w} - \mathbf{y})^T(\mathbf{X}\mathbf{w} - \mathbf{y})$，求导后得到：
    $\hat{\mathbf{w}} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$

2.  **梯度下降 (Gradient Descent)**:
    梯度下降是一种迭代优化算法。它首先随机初始化参数 $\mathbf{w}$，然后沿着代价函数梯度的反方向逐步更新参数，直到收敛。
    
    更新规则为：
    $w_j^{t} = w_j^{t-1} - \alpha \frac{\partial}{\partial w_j}J(\mathbf{w})$，其中 $\alpha$ 是学习率（步长）。

    * **批处理梯度下降 (Batch Gradient Descent)**：每次更新参数时使用所有的训练样本。对于凸函数，它可以保证达到全局最优，但在大样本情况下迭代速度较慢。
    * **随机梯度下降 (Stochastic Gradient Descent)**：每次更新参数时只使用一个训练样本。它的收敛速度较快，对大样本数据更有效，并且有可能跳出局部最优解。也可以采用小批量（Mini-Batch）的方式，即每次使用一小部分样本进行更新。

**梯度下降 vs. 标准方程组**

| 特点         | 梯度下降法                         | 标准方程组                         |
| :----------- | :--------------------------------- | :--------------------------------- |
| 学习率 $\alpha$ | 需要选择                           | 不需要选择                         |
| 迭代次数     | 需要多次迭代                       | 不需要迭代                         |
| 数据归一化   | 通常需要                           | 通常不需要                         |
| 样本量       | 适用于非常大的样本量               | 样本量大时计算 $(\mathbf{X}^T\mathbf{X})^{-1}$ 成本高 |

## 分类：预测离散类别

分类是监督学习的另一个重要问题，其目标是将输入变量分配到预定义的离散类别中。

**线性判别函数**

当类条件概率密度难以直接估计时，我们可以直接设计分类器，即判别函数。线性判别函数是最简单的一种，其形式为：
$$
\begin{aligned}
    g(\mathbf{x}) = \mathbf{w}^T\mathbf{x} + w_0
\end{aligned}
$$

其中 $\mathbf{w}$ 是权向量，$w_0$ 是阈值权。

决策规则通常是：如果 $g(\mathbf{x}) > 0$，则样本属于类别 $C_1$；如果 $g(\mathbf{x}) < 0$，则样本属于类别 $C_2$。
$g(\mathbf{x}) = 0$ 定义了一个决策面，在线性情况下它是一个超平面。向量 $\mathbf{w}$ 是这个超平面的法向量。判别函数 $g(\mathbf{x})$ 的值可以看作是样本点 $\mathbf{x}$ 到决策超平面距离的一种代数度量，其符号表示样本点在超平面的哪一侧。

* **广义线性判别函数**：通过对原始特征进行非线性变换（例如，增加平方项 $x^2$），可以将非线性可分问题转化为高维空间中的线性可分问题，此时的判别函数称为广义线性判别函数。但这也可能导致维度灾难。
* **线性判别函数的齐次化**：通过引入增广样本向量 $\mathbf{y} = [1, \mathbf{x}^T]^T$ 和增广权向量 $\mathbf{a} = [w_0, \mathbf{w}^T]^T$，线性判别函数可以写成齐次形式 $g(\mathbf{x}) = \mathbf{a}^T\mathbf{y}$。这使得决策超平面在增广空间中通过原点，简化了表达和计算。

**线性分类器设计**

设计线性分类器的目标是利用训练样本找到最优的参数 $\mathbf{w}^*$ 和 $w_0^*$（或 $\mathbf{a}^*$。一般步骤如下：
1.  准备带有类别标签的训练样本集。
2.  确定一个准则函数 $J(\mathbf{a})$，它能够反映分类器的性能，其极值对应“最好”的决策。
3.  通过优化算法求解准则函数的极值，得到最优参数。

常见的准则函数包括：

1. **Fisher准则**

旨在找到一个投影方向，使得投影后类间离散度尽可能大，同时类内离散度尽可能小。

以二分类为例，形式化的，我们记各类样本均值为$\tilde{m_i}$，样本类内离散度为
$$
\begin{aligned}
    \tilde{S_i^2} = \sum_{y\in \eta_i}(y - \tilde{m_i})^2
\end{aligned}
$$

其中$y$为样本在一维y空间上的投影

总类内离散度为

$$
\begin{aligned}
    \tilde{S_w} = \sum \tilde{S_i}^2
\end{aligned}
$$

我们希望投影后再一维$\mathbf{Y}$空间中的样本尽量分开，即两类均值之差$\tilde{m_1} - \tilde{m_2}$越大越好。综合来看，我们就能够得到Fisher准则函数：

$$
\begin{aligned}
    \frac{(\tilde{m_1} - \tilde{m_2})^2}{\tilde{S_w}^2}
\end{aligned}
$$

化为矩阵形式后，准则函数为：
$$
\begin{aligned}
    J_F(\mathbf{w}) = \frac{\mathbf{w}^T\mathbf{S}_b\mathbf{w}}{\mathbf{w}^T\mathbf{S}_w\mathbf{w}}
\end{aligned}
$$

其中 $\mathbf{S}_b$ 是类间离散度矩阵，$\mathbf{S}_w$ 是总类内离散度矩阵。最优的投影方向为 $\mathbf{w}^* = \mathbf{S}_w^{-1}(\mathbf{m}_1 - \mathbf{m}_2)$。

2. **感知机准则 (Perceptron Criterion)**：

感知机模型本身是一个二元线性分类器，旨在找到一个超平面，将输入空间中的数据点划分为两个类别。其核心思想是**“错误驱动”**学习，即关注那些被当前模型错误分类的样本，并根据这些错误来调整模型的权重和偏置项，以期在下一次迭代中能够正确分类这些样本，或者至少减少分类的错误程度。

假设我们有一个包含$N$个样本的训练数据集$D = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$，$x_i \in \mathbb{R}^d$ 是 $d$ 维的输入特征向量， $y_i \in \{+1, -1\}$ 是对应的类别标签。感知机模型可以表示为：

$$
\begin{aligned}
    f(x) = \text{sign}(w \cdot x + b)
\end{aligned}
$$

其中：$w$ 是权重向量，维度与输入特征 $x$ 相同。$b$ 是偏置项（或称为阈值）。$w \cdot x$ 表示 $w$ 和 $x$ 的点积。$\text{sign}(\cdot)$ 是符号函数，当其参数大于0时输出+1，小于0时输出-1，等于0时可取+1或-1（具体定义可能略有差异）。感知机准则的目标是找到一组参数 $w$ 和 $b$，使得对于所有训练样本 $(x_i, y_i)$，都有 $y_i(w \cdot x_i + b) > 0$。这意味着所有样本都被正确分类，并且位于分类超平面的正确一侧。

然而，在实际训练过程中，模型不可能一开始就完美分类所有样本。因此，感知机准则定义了一个 **损失函数** 或 **代价函数**，用于量化模型的错误程度。这个损失函数通常只关注那些 **被错误分类的样本**。

对于一个被错误分类的样本 $(x_i, y_i)$，必然满足 $y_i(w \cdot x_i + b) \le 0$。因此感知机准则的损失函数可以定义为：

$$
\begin{aligned}
    L(w, b) = - \sum_{x_i \in M} y_i (w \cdot x_i + b)
\end{aligned}
$$

其中，$M$ 是所有被错误分类的样本的集合。我们的目标就是找到一组$(\omega,b)$，让这个损失函数的值最小，即为0

我们有以下几种方法逐步更新参数：

- 随机梯度下降法：
  
其核心为逐个检查样本，一旦发现错误分类的样本，立即更新参数。对于一个错误分类的样本 $(x_i, y_i)$，即满足 $y_i(w \cdot x_i + b) \le 0$ 的样本，每次以$\eta$的步长更新参数：

$$
\begin{aligned}
    & w \leftarrow w + \eta y_i x_i \\
    & b \leftarrow b + \eta y_i
\end{aligned}
$$

对于线性可分的数据，该方法保证在有限次迭代内收敛，但对于线性不可分数据，算法可能不会收敛，参数会在不同的错误分类样本之间来回震荡。解的质量也可能受到样本遍历顺序的影响。

- 梯度下降法（批量感知机算法）

不再逐个根据单个样本更新，而是遍历所有样本，计算所有错误分类样本产生的总“梯度”或总“修正量”，然后进行一次参数更新。具体来说，每轮迭代都找到一个错分类样本集合$M$，基于这个集合计算参数更新量
$$
\begin{aligned}
    & \Delta w = \sum_{x_i \in M} \eta y_i x_i \\
    & \Delta b = \sum_{x_i \in M} \eta y_i
\end{aligned}
$$

最后更新参数$w \leftarrow w + \Delta w$，$b \leftarrow b + \Delta b$。

该方法更新方向相较于随机选择单个样本更加稳定，但考虑到每次更新前需要遍历整个样本集合，计算成本较高

为节省计算成本，可以在随机法和批量法之间取一个折中，即每次从训练数据中取一小部分样本$\text{minibatch}$，然后基于这个$\text{minibatch}$计算参数更新量

3. **最小二乘准则 (Least Squares Criterion)**：旨在最小化预测值与目标值之间误差的平方和。对于分类问题，可以为不同类别的样本设置不同的目标值（例如，属于类别 $w_1$ 的样本目标值为 $b_1 > 0$，属于类别 $w_2$ 的样本目标值为 $b_2 < 0$，通常是将样本规范化后，目标值设为正数）。设增广样本矩阵为 $\mathbf{Y}$，目标值向量为 $\mathbf{b}$，则目标是找到权向量 $\mathbf{a}$ 使得 $\|\mathbf{Y}\mathbf{a} - \mathbf{b}\|^2$ 最小。其解析解（伪逆解）为 $\mathbf{a}^* = (\mathbf{Y}^T\mathbf{Y})^{-1}\mathbf{Y}^T\mathbf{b}$。也可以使用梯度下降法求解。最小二乘法对异常值（Outlier）非常敏感。


# 解密决策树：从基本概念到高级技巧

决策树是一种广泛应用于机器学习领域的强大工具，它通过一系列简单直观的规则来辅助决策和分类。本文将带您深入了解决策树的核心概念、主要算法以及在实践中可能遇到的挑战与解决方案。

## 什么是决策树？

想象一下，您在决定是否要出门打网球。您可能会考虑天气（晴朗、阴天、下雨？）、湿度（高、正常？）、风力（强、弱？）等因素。决策树就像是把这个决策过程可视化，它是一个树状结构，其中：

* **内部节点**：代表一个“问题”或“属性”（例如，“天气如何？”）。
* **分支**：代表该问题的一个可能“答案”或“属性值”（例如，“晴朗”）。
* **叶节点**：代表最终的“决策”或“分类结果”（例如，“适合打网球”或“不适合打网球”）。

通过从根节点开始，根据实际情况回答一系列问题，沿着相应的分支向下，最终就能到达一个叶节点，从而得到决策结果。这种方法不仅直观，还可以看作是一系列“如果...那么...”规则的集合。

## 构建决策树：核心算法

构建决策树的关键在于如何选择最优的属性来进行划分，目标是让每个分支下的数据尽可能属于同一类别，即节点的“纯度”越来越高。以下是几种主流的决策树生成算法：

### ID3

ID3 (Iterative Dichotomiser 3) 算法的核心思想是采用自顶向下的递归方法，利用信息论中的熵和信息增益作为属性选择的度量标准，从而构建一棵能够对数据进行有效分类的决策树。

为了理解ID3算法，首先需要掌握两个关键的信息论概念：

1.  **信息熵 (Information Entropy)**

在信息论中，熵是衡量一个随机变量不确定性大小的度量。对于一个样本集合 $D$，假设其中包含 $C$ 个不同的类别，第 $c$ 类样本所占的比例为 $p_c$ ( $c=1, 2, ..., C$ )，则集合 $D$ 的经验信息熵定义为：
$$
\begin{aligned}
    H(D) = -\sum_{c=1}^{C} p_c \log_{2} p_c
\end{aligned}
$$

其中，$p_c = \frac{|D_c|}{|D|}$，$|D_c|$ 是属于第 $c$ 类的样本数量，$|D|$ 是样本总数。$H(D)$ 的值越小，表示样本集合 $D$ 的纯度越高，即不确定性越小。当集合中所有样本都属于同一类别时，熵为0；当样本均匀分布在各个类别时，熵达到最大值。ID3算法的目标就是通过选择合适的属性来不断降低子集的熵，从而使得划分后的数据更有序。

2. **条件熵 (Conditional Entropy)**

条件熵 $H(Y|X)$ 表示在已知随机变量 $X$ 的条件下，随机变量 $Y$ 的不确定性。在决策树的上下文中，假设我们选择属性 $a$ 来划分数据集 $D$。属性 $a$ 有 $N$ 个可能的取值 $\{a_1, a_2, ..., a_N\}$，根据属性 $a$ 的不同取值，可以将数据集 $D$ 划分为 $N$ 个子集 $D^1, D^2, ..., D^N$。那么，在给定属性 $a$ 的条件下，数据集 $D$ 的经验条件熵 $H(D|a)$ 定义为：
$$H(D|a) = \sum_{n=1}^{N} \frac{|D^n|}{|D|} H(D^n)$$
这里，$|D^n|$ 是属性 $a$ 取值为 $a_n$ 的样本子集的大小，$H(D^n)$ 是该子集的经验信息熵。

3. **信息增益 (Information Gain)**

信息增益是ID3算法进行属性选择的核心度量。它表示在得知某一属性 $a$ 的信息后，使得数据集 $D$ 的不确定性减少的程度（即熵的下降程度）。特征 $a$ 对训练数据集 $D$ 的信息增益 $G(D,a)$ 定义为集合 $D$ 的经验熵 $H(D)$ 与特征 $a$ 给定条件下的经验条件熵 $H(D|a)$ 之差：

$$G(D,a) = H(D) - H(D|a)$$
$$G(D,a) = H(D) - \sum_{n=1}^{N} \frac{|D^n|}{|D|} H(D^n)$$

ID3算法在每一步选择节点时，会计算所有候选属性的信息增益，并选择那个使得信息增益最大的属性作为当前节点的划分属性。其直观意义是，选择这个属性进行划分，能够最大程度地降低数据集的混乱程度，使得划分后的子集尽可能地“纯净”。


### C4.5

ID3 算法使用信息增益作为属性选择标准时，存在一个显著的偏好，即倾向于选择那些具有较多取值的属性，即使这些属性的实际分类能力并不强。为了克服这一缺陷，C4.5 引入了**信息增益率**。

信息增益率的定义为信息增益 $G(D,a)$ 与属性 $a$ 的“固有值”(Intrinsic Value) 或称“分裂信息”(Split Information) $H(a)$ 的比率：

$$G_{ratio}(D,a) = \frac{G(D,a)}{H(a)}$$

其中，属性 $a$ 的固有值 $H(a)$ 定义为：

$$H(a) = -\sum_{n=1}^{N} \frac{|D_n|}{|D|} \log_{2} \frac{|D_n|}{|D|}$$

这里，$N$ 是属性 $a$ 的不同取值的数量，$|D_n|$ 是数据集中属性 $a$ 取第 $n$ 个值的样本数量，$|D|$ 是数据集的总样本数量。属性的取值越多，$H(a)$ 的值通常也越大。通过将信息增益除以这个固有值，C4.5 算法能够对取值数目较多的属性进行“惩罚”，从而缓解了 ID3 算法的偏好性，使得属性选择更为公平和合理。
值得注意的是，C4.5 并非直接选择信息增益率最大的属性，而是采用一种启发式策略：先从候选属性中找出信息增益高于平均水平的属性，然后再从这些属性中选择信息增益率最高的。这样做是为了避免分裂信息 $H(a)$ 过小（例如属性取值非常少时）导致信息增益率被不成比例地放大。

### CART (Classification and Regression Trees)

CART (Classification and Regression Trees) 算法是一种广泛应用的决策树构建算法，由 Breiman 等人于1984年提出。与 ID3 和 C4.5 算法不同，CART 算法生成的决策树是严格的二叉树，即每个非叶节点只有两个分支。这一特性使得 CART 树的结构更为简洁。CART 算法既可以用于分类任务，也可以用于回归任务，其核心思想是通过递归地将当前样本集划分为两个子集，使得划分后的纯度（分类树）或均方误差（回归树）最优。

在构建分类树时，CART算法采用**基尼指数 (Gini Index)** 作为选择最优划分属性和最优划分点的标准。

**数据集的基尼指数**：基尼指数衡量的是从数据集中随机抽取两个样本，其类别标记不一致的概率。因此，基尼指数越小，数据集的纯度越高。对于一个给定的样本集 $D$，假设有 $C$ 个类别，第 $c$ 类样本所占的比例为 $p_c$，则数据集 $D$ 的基尼指数定义为：

$$Gini(D) = \sum_{c=1}^{C} \sum_{c' \neq c} p_c p_{c'} = 1 - \sum_{c=1}^{C} p_c^2 = 1 - \sum_{c=1}^{C} \left(\frac{|D_c|}{|D|}\right)^2$$

其中，$|D_c|$ 是属于第 $c$ 类的样本数量，$|D|$ 是样本总数。

**属性划分的基尼指数**：当根据属性 $a$ 的某个可能取值（或对于连续属性的某个划分点）将数据集 $D$ 分为两个子集 $D_1$ 和 $D_2$ 时，划分后的基尼指数定义为这两个子集基尼指数的加权平均：

$$Gini(D, a) = \frac{|D_1|}{|D|} Gini(D_1) + \frac{|D_2|}{|D|} Gini(D_2)$$

CART 算法的目标是选择一个属性 $a$ 和该属性的一个划分方式（对于离散属性是值的二分组合，对于连续属性是一个阈值），使得划分后的 $Gini(D, a)$ 最小。即最优划分属性 $a^*$ 和最优划分方式的选择标准为：

$$a^* = \arg\min_{a \in A} Gini(D, a)$$

CART 分类树的生成是一个递归地构建二叉树的过程：

1.  **遍历属性与划分点**：
    * **对于离散属性 $a$**：如果属性 $a$ 有多个取值，CART 会遍历所有可能的二分组合。例如，如果属性 $a$ 有 $\{v_1, v_2, v_3\}$ 三个取值，可能的二分方式有 $\{\{v_1\}, \{v_2, v_3\}\}$，$\{\{v_2\}, \{v_1, v_3\}\}$，$\{\{v_3\}, \{v_1, v_2\}\}$。对每一种二分方式，将数据集 $D$ 划分为 $D_1$ 和 $D_2$，然后计算该划分的基尼指数 $Gini(D,a)$。
    * **对于连续属性 $a$**：CART 首先将样本按该属性值从小到大排序。然后，遍历所有可能的划分点（通常是相邻两个不同属性值的平均数）。对每个划分点 $t$，将数据集 $D$ 分为 $D_1$（属性值 $\le t$）和 $D_2$（属性值 $> t$），并计算该划分的基尼指数 $Gini(D,a)$。

2.  **选择最优划分**：
    在所有属性的所有可能二分划分中，选择使得划分后基尼指数最小的那个属性和相应的划分方式作为当前节点的最优划分。

3.  **生成子节点**：
    根据最优划分将当前节点的数据集划分为两个子集，并生成两个子节点。

4.  **递归构建**：
    对这两个子节点递归地重复上述步骤，直到满足停止条件。停止条件通常包括：
    * 节点中的样本数量小于预设阈值。
    * 节点中所有样本都属于同一类别。
    * 节点的基尼指数小于预设阈值（即节点已足够纯）。
    * 继续划分不能再显著降低基尼指数。

5.  **生成决策树**：
    最终得到一棵二叉决策树。

## 决策树的挑战与优化

在实际应用中，决策树可能会遇到一些问题，需要相应的策略进行优化：

1.  **过拟合 (Overfitting)**：决策树在训练数据上表现很好，但在新的、未见过的数据上表现较差的现象。这可能是因为决策树过于复杂，学习到了训练数据中的噪声或一些偶然的规律。
    * **剪枝 (Pruning)**：是解决过拟合的主要手段。
        * **预剪枝 (Pre-pruning)**：在决策树生成过程中，对每个节点在划分前进行评估，如果划分不能带来泛化性能的提升，则停止划分。这样做可以减少训练时间和过拟合风险，但可能导致欠拟合。
        * **后剪枝 (Post-pruning)**：先生成一棵完整的决策树，然后自底向上对非叶节点进行考察，如果将其替换为叶节点能提升泛化性能，则进行替换。这种方法通常能带来更好的泛化性能，但训练开销更大。 

2.  **处理连续值属性**：像ID3这样的早期算法无法直接处理连续值的属性。 [cite: 29] C4.5等算法采用二分法对连续属性进行离散化处理。 [cite: 67] 具体做法是，将连续属性的取值排序，然后选择最佳的分割点将数据分为两部分，计算信息增益（或增益率、基尼指数），并选择最优的分割点。 [cite: 67, 68]

3.  **处理缺失值**：实际数据中常常存在某些属性值缺失的情况。 [cite: 74] C4.5算法提供了一种处理缺失值的方法：
    * **属性选择时**：仅使用在当前属性上没有缺失值的样本来计算信息增益。 [cite: 78]
    * **划分样本时**：如果样本在某个属性上的值缺失，可以将该样本以一定的权重（基于已知值的样本分布）分配到所有子节点中。 [cite: 81]

4.  **处理不同代价的属性**：在某些应用场景（如医疗诊断）中，获取不同属性值的代价可能不同。 [cite: 88] 此时，可以在属性选择标准中引入代价因素，例如将信息增益除以代价，或使用更复杂的代价敏感函数，优先选择低代价的属性。 [cite: 89]

## 总结

决策树作为一种直观且强大的机器学习模型，在分类和回归任务中都有着广泛的应用。理解其基本原理、核心算法以及如何处理过拟合、连续值、缺失值和不同代价属性等常见问题，对于有效地应用决策树至关重要。通过不断地研究和改进，决策树算法家族也在持续发展，为解决更复杂的现实问题提供支持。